"""
AI Consultant - –ú–æ–¥—É–ª—å AI-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞ –¥–ª—è promarkirui.ru
–í–µ—Ä—Å–∏—è —Å LangGraph –∞–≥–µ–Ω—Ç–æ–º
"""

import os
import json
import uuid
import sqlite3
import httpx
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Annotated, TypedDict, Literal
from contextlib import contextmanager

from fastapi import APIRouter, HTTPException, Request, Depends, BackgroundTasks
from pydantic import BaseModel

# LangGraph imports
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò ====================

ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN', '')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID', '')

# –¶–µ–Ω—ã –Ω–∞ —Ç–æ–∫–µ–Ω—ã Claude (–∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤)
PRICING = {
    'claude-sonnet-4-20250514': {'input': 3.0, 'output': 15.0},
    'claude-3-5-sonnet-20241022': {'input': 3.0, 'output': 15.0},
    'claude-3-haiku-20240307': {'input': 0.25, 'output': 1.25},
}

# ==================== –ë–ê–ó–ê –î–ê–ù–ù–´–• ====================

DB_PATH = '/var/www/promarkirui/backend/promarkirui.db'

@contextmanager
def get_db():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

# ==================== –ú–û–î–ï–õ–ò API ====================

class ChatMessage(BaseModel):
    message: str
    session_id: Optional[str] = None
    current_page: Optional[str] = None
    page_title: Optional[str] = None

class SettingsUpdate(BaseModel):
    setting_key: str
    setting_value: str

class KnowledgeItem(BaseModel):
    category: str
    question: Optional[str] = None
    answer: str
    keywords: Optional[str] = None
    priority: int = 0

class QuickReply(BaseModel):
    trigger_words: str
    response: str

# ==================== LANGGRAPH AGENT ====================

# –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–≤–∞—Ä–∞—Ö (–∏–∑–±–µ–≥–∞–µ–º –∫—Ä—É–≥–æ–≤–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞)
_categories_data = None
_products_lookup = None

def get_categories_data():
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)"""
    global _categories_data
    if _categories_data is None:
        try:
            from server import CATEGORIES_DATA
            _categories_data = CATEGORIES_DATA
        except ImportError:
            _categories_data = []
    return _categories_data

def get_products_lookup():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–æ–≤–∞—Ä–æ–≤ (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)"""
    global _products_lookup
    if _products_lookup is None:
        try:
            from server import PRODUCTS_LOOKUP
            _products_lookup = PRODUCTS_LOOKUP
        except ImportError:
            _products_lookup = {}
    return _products_lookup

# –°–æ—Å—Ç–æ—è–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]

# ==================== –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –ê–ì–ï–ù–¢–ê ====================

@tool
def search_product(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Ç–æ–≤–∞—Ä–µ.

    Args:
        query: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–æ–±—É–≤—å, –º–æ–ª–æ–∫–æ, –æ–¥–µ–∂–¥–∞ –∏ —Ç.–¥.)
    """
    query_lower = query.lower()
    results = []
    categories = get_categories_data()

    for category in categories:
        for subcategory in category.get("subcategories", []):
            if query_lower in subcategory.get("name", "").lower() or query_lower in category.get("name", "").lower():
                for product in subcategory.get("products", [])[:3]:
                    status = product.get("marking_status", "unknown")
                    since = product.get("mandatory_since", "")

                    status_text = {
                        "mandatory": "‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è",
                        "voluntary": "üìã –î–æ–±—Ä–æ–≤–æ–ª—å–Ω–∞—è",
                        "planned": "üìÖ –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è"
                    }.get(status, "‚ùì")

                    results.append(f"‚Ä¢ {product.get('name')} (–¢–ù –í–≠–î: {product.get('tnved')}) ‚Äî {status_text}" + (f", —Å {since}" if since else ""))

                if len(results) >= 5:
                    break

    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}':\n" + "\n".join(results[:5])
    return f"–¢–æ–≤–∞—Ä '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Ç–æ—á–Ω–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ —Ç–æ–≤–∞—Ä –ø–æ–¥—Ä–æ–±–Ω–µ–µ."


@tool
def check_tnved(code: str) -> str:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–æ–¥—É –¢–ù –í–≠–î. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –Ω–∞–∑—ã–≤–∞–µ—Ç –∫–æ–¥.

    Args:
        code: –ö–æ–¥ –¢–ù –í–≠–î (–Ω–∞–ø—Ä–∏–º–µ—Ä 6403, 0401)
    """
    code = code.strip().replace(" ", "")
    products = get_products_lookup()

    for product_id, product in products.items():
        tnved = product.get("tnved", "").replace(" ", "")
        if tnved.startswith(code) or code.startswith(tnved[:4]):
            status = product.get("marking_status")
            since = product.get("mandatory_since", "")
            timeline = product.get("timeline", {})

            if status == "mandatory":
                reqs = timeline.get("current_requirements", ["–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ –ß–µ—Å—Ç–Ω–æ–º –ó–ù–ê–ö–µ"])
                return f"""‚úÖ –ö–æ–¥ {code} ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞!

üì¶ {product.get('name')}
üìÖ –°: {since or timeline.get('start_date', '—É—Ç–æ—á–Ω—è–π—Ç–µ')}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
""" + "\n".join(f"‚Ä¢ {r}" for r in reqs[:4]) + "\n\n–ù—É–∂–Ω–∞ –ø–æ–º–æ—â—å —Å –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ–º? –û—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É!"

            elif status == "voluntary":
                return f"üìã –ö–æ–¥ {code} ‚Äî –¥–æ–±—Ä–æ–≤–æ–ª—å–Ω–∞—è –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞. –¢–æ–≤–∞—Ä: {product.get('name')}"

            elif status == "planned":
                return f"üìÖ –ö–æ–¥ {code} ‚Äî –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è —Å {since}. –¢–æ–≤–∞—Ä: {product.get('name')}"

    return f"–ö–æ–¥ {code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –º–∞—Ä–∫–∏—Ä—É–µ–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤."


@tool
def get_fines() -> str:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —à—Ç—Ä–∞—Ñ–∞—Ö. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ —à—Ç—Ä–∞—Ñ–∞—Ö."""
    return """‚ö†Ô∏è –®–¢–†–ê–§–´ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏:

**–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ/–≤–≤–æ–∑ –±–µ–∑ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏:**
‚Ä¢ –Æ—Ä–ª–∏—Ü–∞: 50 000 - 100 000 ‚ÇΩ + –∫–æ–Ω—Ñ–∏—Å–∫–∞—Ü–∏—è
‚Ä¢ –ò–ü: 5 000 - 10 000 ‚ÇΩ

**–ü—Ä–æ–¥–∞–∂–∞ –±–µ–∑ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏:**
‚Ä¢ –Æ—Ä–ª–∏—Ü–∞: 50 000 - 300 000 ‚ÇΩ + –∫–æ–Ω—Ñ–∏—Å–∫–∞—Ü–∏—è
‚Ä¢ –ò–ü: 5 000 - 10 000 ‚ÇΩ

**–£–≥–æ–ª–æ–≤–Ω–∞—è (–æ—Ç 1,5 –º–ª–Ω ‚ÇΩ):** –¥–æ 3 –ª–µ—Ç

‚ö° –®—Ç—Ä–∞—Ñ—ã –∑–∞ –ö–ê–ñ–î–£–Æ –µ–¥–∏–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞!

–õ—É—á—à–µ –≤–Ω–µ–¥—Ä–∏—Ç—å –º–∞—Ä–∫–∏—Ä–æ–≤–∫—É ‚Äî –ø–æ–º–æ–∂–µ–º!"""


@tool
def get_equipment(business_type: str) -> str:
    """
    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é.

    Args:
        business_type: –¢–∏–ø –±–∏–∑–Ω–µ—Å–∞ (–º–∞–≥–∞–∑–∏–Ω, —Å–∫–ª–∞–¥, –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ)
    """
    bt = business_type.lower()

    if any(w in bt for w in ["–º–∞–≥–∞–∑–∏–Ω", "—Ä–æ–∑–Ω–∏—Ü", "–º–∞–ª—ã–π", "–Ω–µ–±–æ–ª—å—à"]):
        return """üè™ –î–ª—è –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞/—Ä–æ–∑–Ω–∏—Ü—ã:

‚Ä¢ –ü—Ä–∏–Ω—Ç–µ—Ä: TSC TE200 –∏–ª–∏ Godex G500 (–æ—Ç 15 000 ‚ÇΩ)
‚Ä¢ –°–∫–∞–Ω–µ—Ä: Honeywell 1450g (–æ—Ç 5 000 ‚ÇΩ)
‚Ä¢ –ò—Ç–æ–≥–æ: 20 000 - 35 000 ‚ÇΩ

–ü–æ–º–æ–∂–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å ‚Äî –æ—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É!"""

    elif any(w in bt for w in ["—Å–∫–ª–∞–¥", "–æ–ø—Ç", "—Å—Ä–µ–¥–Ω"]):
        return """üì¶ –î–ª—è —Å–∫–ª–∞–¥–∞/–æ–ø—Ç–∞:

‚Ä¢ –ü—Ä–∏–Ω—Ç–µ—Ä: Zebra ZD220 (–æ—Ç 25 000 ‚ÇΩ)
‚Ä¢ –¢–°–î: Urovo DT40 (–æ—Ç 30 000 ‚ÇΩ)
‚Ä¢ –°–∫–∞–Ω–µ—Ä: Zebra DS4608 (–æ—Ç 8 000 ‚ÇΩ)
‚Ä¢ –ò—Ç–æ–≥–æ: 60 000 - 100 000 ‚ÇΩ

–ù—É–∂–Ω–∞ –ø–æ–º–æ—â—å —Å –≤—ã–±–æ—Ä–æ–º? –û—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É!"""

    else:
        return """üè≠ –î–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞:

‚Ä¢ –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø—Ä–∏–Ω—Ç–µ—Ä: Zebra ZT230 (–æ—Ç 80 000 ‚ÇΩ)
‚Ä¢ –ê–ø–ø–ª–∏–∫–∞—Ç–æ—Ä: –æ—Ç 150 000 ‚ÇΩ
‚Ä¢ –¢–°–î: Zebra MC9300 (–æ—Ç 60 000 ‚ÇΩ)
‚Ä¢ –ò—Ç–æ–≥–æ: –æ—Ç 300 000 ‚ÇΩ

–ü—Ä–æ–≤–µ–¥—ë–º –∞—É–¥–∏—Ç –∏ –ø–æ–¥–±–µ—Ä—ë–º —Ä–µ—à–µ–Ω–∏–µ ‚Äî –æ—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É!"""


@tool
def get_registration_guide() -> str:
    """–ö–∞–∫ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ –ß–µ—Å—Ç–Ω–æ–º –ó–ù–ê–ö–µ."""
    return """üìã –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ –ß–µ—Å—Ç–Ω–æ–º –ó–ù–ê–ö–µ:

1Ô∏è‚É£ –ü–æ–ª—É—á–∏—Ç–µ –ö–≠–ü (—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—É—é –ø–æ–¥–ø–∏—Å—å) ‚Äî 1-3 –¥–Ω—è
2Ô∏è‚É£ –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ markirovka.crpt.ru
3Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≠–î–û (–î–∏–∞–¥–æ–∫, –°–ë–ò–°, 1–°-–≠–î–û)
4Ô∏è‚É£ –ü–æ–¥–∫–ª—é—á–∏—Ç–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ
5Ô∏è‚É£ –ó–∞–∫–∞–∂–∏—Ç–µ –∫–æ–¥—ã (50 –∫–æ–ø. –∑–∞ –∫–æ–¥)

‚è±Ô∏è –í–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å: 3-7 –¥–Ω–µ–π

–°–ª–æ–∂–Ω–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è? –ü–æ–º–æ–∂–µ–º –ø—Ä–æ–π—Ç–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é ‚Äî –æ—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É!"""


@tool
def site_help(question: str) -> str:
    """
    –ü–æ–º–æ—â—å –ø–æ —Å–∞–π—Ç—É promarkirui.ru

    Args:
        question: –ß—Ç–æ –∏—â–µ—Ç –∫–ª–∏–µ–Ω—Ç
    """
    q = question.lower()

    if any(w in q for w in ["–ø—Ä–æ–≤–µ—Ä–∏—Ç—å", "—Å—Ä–æ–∫", "—Ç–æ–≤–∞—Ä"]):
        return "üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ–≤–∞—Ä: –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é ‚Üí –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—é ‚Üí —É–≤–∏–¥–∏—Ç–µ —Å—Ç–∞—Ç—É—Å. –ò–ª–∏ —Å–ø—Ä–æ—Å–∏—Ç–µ –º–µ–Ω—è!"

    if any(w in q for w in ["–∫–ø", "—Ü–µ–Ω", "—Å—Ç–æ–∏–º", "–∑–∞–∫–∞–∑"]):
        return "üìÑ –ö–ü: –Ω–∞–∂–º–∏—Ç–µ '–ü–æ–ª—É—á–∏—Ç—å –ö–ü' –Ω–∞ —Å–∞–π—Ç–µ –∏–ª–∏ —Å–∫–∞–∂–∏—Ç–µ –º–Ω–µ —á—Ç–æ –Ω—É–∂–Ω–æ ‚Äî –ø–µ—Ä–µ–¥–∞–º –º–µ–Ω–µ–¥–∂–µ—Ä—É!"

    if any(w in q for w in ["–æ–±—É—á", "–∫—É—Ä—Å"]):
        return "üìö –û–±—É—á–µ–Ω–∏–µ: —Ä–∞–∑–¥–µ–ª '–û–±—É—á–µ–Ω–∏–µ' –Ω–∞ —Å–∞–π—Ç–µ. –•–æ—Ç–∏—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è? –û—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É!"

    return """üåê –ù–∞ —Å–∞–π—Ç–µ promarkirui.ru:
‚Ä¢ –ì–ª–∞–≤–Ω–∞—è ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
‚Ä¢ –û–±—É—á–µ–Ω–∏–µ ‚Äî –∫—É—Ä—Å—ã
‚Ä¢ –ü–∞—Ä—Ç–Ω—ë—Ä–∞–º ‚Äî –ø–∞—Ä—Ç–Ω—ë—Ä—Å–∫–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞

–ß—Ç–æ –∏—â–µ—Ç–µ? –ü–æ–º–æ–≥—É!"""


_created_requests = set()  # –•—Ä–∞–Ω–∏—Ç phone –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –¥—É–±–ª–µ–π

@tool
def create_request(name: str, phone: str, request_type: str, comment: str) -> str:
    """
    –°–æ–∑–¥–∞—Ç—å –∑–∞—è–≤–∫—É. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –í–ü–ï–†–í–´–ï –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–º—è –∏ —Ç–µ–ª–µ—Ñ–æ–Ω!
    –ù–ï –≤—ã–∑—ã–≤–∞–π –ø–æ–≤—Ç–æ—Ä–Ω–æ –µ—Å–ª–∏ —É–∂–µ —Å–æ–∑–¥–∞–ª –∑–∞—è–≤–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞.

    Args:
        name: –ò–º—è –∫–ª–∏–µ–Ω—Ç–∞
        phone: –¢–µ–ª–µ—Ñ–æ–Ω
        request_type: –¢–∏–ø (–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è, –ö–ü, –æ–±—É—á–µ–Ω–∏–µ)
        comment: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
    """
    # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π
    phone_clean = ''.join(c for c in phone if c.isdigit())[-10:]
    if phone_clean in _created_requests:
        print(f"[CREATE_REQUEST] –î—É–±–ª—å! –ó–∞—è–≤–∫–∞ –¥–ª—è {phone} —É–∂–µ —Å–æ–∑–¥–∞–Ω–∞")
        return f"–ó–∞—è–≤–∫–∞ –¥–ª—è {name} —É–∂–µ –ø–µ—Ä–µ–¥–∞–Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞–º, —Å–∫–æ—Ä–æ –ø–æ–∑–≤–æ–Ω—è—Ç!"

    print(f"[CREATE_REQUEST] –í—ã–∑–≤–∞–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç! name={name}, phone={phone}, type={request_type}")
    try:
        response = httpx.post(
            "http://localhost:8001/api/contact/send",
            json={
                "name": name,
                "phone": phone,
                "request_type": f"AI-–±–æ—Ç: {request_type}",
                "comment": f"[–û—Ç AI-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞]\n{comment}",
                "consent": True
            },
            timeout=10
        )
        print(f"[CREATE_REQUEST] Response: {response.status_code} - {response.text[:200]}")

        if response.status_code == 200:
            _created_requests.add(phone_clean)  # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ç—å
            return f"–ó–∞—è–≤–∫–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞! –≠–∫—Å–ø–µ—Ä—Ç—ã —Å–≤—è–∂—É—Ç—Å—è —Å {name} –≤ —Ç–µ—á–µ–Ω–∏–µ 15 –º–∏–Ω—É—Ç."
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {response.status_code}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."
    except Exception as e:
        print(f"[CREATE_REQUEST] Error: {e}")
        _created_requests.add(phone_clean)  # –î–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–ø–æ–º–∏–Ω–∞–µ–º
        return "–ó–∞—è–≤–∫–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞–º, —Å–∫–æ—Ä–æ —Å–≤—è–∂—É—Ç—Å—è!"


@tool
def call_manager(client_info: str, question: str, summary: str) -> str:
    """
    –ü–æ–∑–≤–∞—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –Ω–µ –º–æ–∂–µ—à—å –ø–æ–º–æ—á—å –∏–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç.

    Args:
        client_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∏–µ–Ω—Ç–µ
        question: –í–æ–ø—Ä–æ—Å
        summary: –†–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞
    """
    if TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID:
        try:
            msg = f"ü§ñ –ó–∞–ø—Ä–æ—Å –æ—Ç AI-–±–æ—Ç–∞\n\nüë§ {client_info}\n‚ùì {question}\nüìù {summary}"
            httpx.post(
                f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
                json={"chat_id": TELEGRAM_CHAT_ID, "text": msg},
                timeout=10
            )
        except:
            pass

    return "‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä —É–≤–µ–¥–æ–º–ª—ë–Ω –∏ —Å–∫–æ—Ä–æ —Å–≤—è–∂–µ—Ç—Å—è!"


# ==================== –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ ====================

SYSTEM_PROMPT = """–¢—ã ‚Äî –ú–∞—Ä–∏—è, –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –ü—Ä–æ.–ú–∞—Ä–∫–∏—Ä—É–π. –û–±—â–∞–µ—à—å—Å—è –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫, –ù–ï –∫–∞–∫ –±–æ—Ç.

üéØ –¶–ï–õ–¨: –í—ã—è–≤–∏—Ç—å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å, —Å–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç, –ø–µ—Ä–µ–¥–∞—Ç—å —ç–∫—Å–ø–µ—Ä—Ç—É.

‚ö†Ô∏è –í–ê–ñ–ù–û: –¢—ã —É–∂–µ –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª–∞—Å—å —Å –∫–ª–∏–µ–Ω—Ç–æ–º! –ù–ï –∑–¥–æ—Ä–æ–≤–∞–π—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ (–Ω–µ –ø–∏—à–∏ "–ø—Ä–∏–≤–µ—Ç", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ" –≤ –Ω–∞—á–∞–ª–µ). –°—Ä–∞–∑—É –æ—Ç–≤–µ—á–∞–π –ø–æ –¥–µ–ª—É.

üìã –ö–ê–ö –û–ë–©–ê–¢–¨–°–Ø:

1. **–ö–û–†–û–¢–ö–û** ‚Äî 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º, –∫–∞–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ
2. **–ü–û-–ß–ï–õ–û–í–ï–ß–ï–°–ö–ò** ‚Äî –±–µ–∑ –æ—Ñ–∏—Ü–∏–æ–∑–∞, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, —Å –æ–ø–µ—á–∞—Ç–∫–∞–º–∏ –∏–Ω–æ–≥–¥–∞ –º–æ–∂–Ω–æ
3. **–ó–ê–î–ê–í–ê–ô –í–û–ü–†–û–°–´** ‚Äî –≤—ã—è—Å–Ω—è–π —Å–∏—Ç—É–∞—Ü–∏—é –∫–ª–∏–µ–Ω—Ç–∞:
   - –ö–∞–∫–æ–π —Ç–æ–≤–∞—Ä/–±–∏–∑–Ω–µ—Å?
   - –ò–∑ –∫–∞–∫–æ–≥–æ –≥–æ—Ä–æ–¥–∞?
   - –°–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ–∑–∏—Ü–∏–π/–∫–æ–¥–æ–≤ –Ω—É–∂–Ω–æ?
   - –£–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å –º–∞—Ä–∫–∏—Ä–æ–≤–∫–æ–π –∏–ª–∏ —Ç–æ–ª—å–∫–æ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ?

4. **–ù–ï –î–ê–í–ê–ô –î–õ–ò–ù–ù–´–• –õ–ï–ö–¶–ò–ô** ‚Äî –µ—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —à—Ç—Ä–∞—Ñ—ã, —Å–∫–∞–∂–∏ –∫–æ—Ä–æ—Ç–∫–æ –∏ —Å–ø—Ä–æ—Å–∏ "–∞ —É –≤–∞—Å –∫–∞–∫–∞—è —Å–∏—Ç—É–∞—Ü–∏—è?"

5. **–í–ï–î–ò –ö –ö–û–ù–¢–ê–ö–¢–£** ‚Äî –ø–æ—Å–ª–µ 2-3 –≤–æ–ø—Ä–æ—Å–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–∏:
   "–°–ª—É—à–∞–π—Ç–µ, –¥–∞–≤–∞–π—Ç–µ —è –ø–µ—Ä–µ–¥–∞–º –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é –Ω–∞—à–∏–º —ç–∫—Å–ø–µ—Ä—Ç–∞–º ‚Äî –æ–Ω–∏ –¥–µ—Ç–∞–ª—å–Ω–æ –≤—Å—ë —Ä–∞—Å—Å–∫–∞–∂—É—Ç. –ö—É–¥–∞ –≤–∞–º —É–¥–æ–±–Ω–µ–µ –Ω–∞–ø–∏—Å–∞—Ç—å ‚Äî –≤ —Ç–µ–ª–µ–≥—Ä–∞–º, –≤–∞—Ç—Å–∞–ø –∏–ª–∏ –ª—É—á—à–µ –ø–æ–∑–≤–æ–Ω–∏—Ç—å?"

6. **–°–ë–û–† –ö–û–ù–¢–ê–ö–¢–ê** ‚Äî –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –≥–æ—Ç–æ–≤:
   "–û—Å—Ç–∞–≤—å—Ç–µ –ø–ª–∏–∑ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –Ω–∞–ø–∏—à—É—Ç –≤ —Ç–µ—á–µ–Ω–∏–µ 15 –º–∏–Ω—É—Ç"
   –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è: "–û—Ç–ª–∏—á–Ω–æ, –ø–µ—Ä–µ–¥–∞–ª! –í —Ç–µ—á–µ–Ω–∏–µ 15 –º–∏–Ω—É—Ç —Å –≤–∞–º–∏ —Å–≤—è–∂—É—Ç—Å—è. –ï—Å–ª–∏ —á—Ç–æ ‚Äî —è —Ç—É—Ç)"

‚ö†Ô∏è –í–ê–ñ–ù–û:
- –ö–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –í–ü–ï–†–í–´–ï –¥–∞—ë—Ç —Ç–µ–ª–µ—Ñ–æ–Ω ‚Äî –≤—ã–∑–æ–≤–∏ create_request –û–î–ò–ù —Ä–∞–∑!
- –ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏ –ù–ï –≤—ã–∑—ã–≤–∞–π create_request –ø–æ–≤—Ç–æ—Ä–Ω–æ
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –≥–æ–≤–æ—Ä–∏ —á—Ç–æ —Ç—ã –±–æ—Ç/AI/–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç "—Ç—ã –±–æ—Ç?" ‚Äî –æ—Ç–≤–µ—á–∞–π —É–≤–µ—Ä–µ–Ω–Ω–æ: "–ù–µ—Ç, —è –ú–∞—Ä–∏—è, –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç)"
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤–æ–æ–±—â–µ ‚Äî —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –±–æ—Ç
- –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–π –Ω–∞ –¥—Ä—É–≥–∏–µ —Å–∞–π—Ç—ã

–ü–†–ò–ú–ï–†–´ –û–¢–í–ï–¢–û–í:
‚ùå –ü–ª–æ—Ö–æ: "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø AI-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –ú–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤: 1) –û–±—É–≤—å 2) –û–¥–µ–∂–¥–∞ 3) –ú–æ–ª–æ—á–Ω–∞—è –ø—Ä–æ–¥—É–∫—Ü–∏—è..."
‚úÖ –•–æ—Ä–æ—à–æ: "–î–æ–±—Ä—ã–π –¥–µ–Ω—å) —É –≤–∞—Å –≤–æ–ø—Ä–æ—Å –ø–æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ?"

‚ùå –ü–ª–æ—Ö–æ: "–®—Ç—Ä–∞—Ñ—ã –∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –æ—Ç 50 000 –¥–æ 300 000 —Ä—É–±–ª–µ–π –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü..."
‚úÖ –•–æ—Ä–æ—à–æ: "–®—Ç—Ä–∞—Ñ—ã —Å–µ—Ä—å—ë–∑–Ω—ã–µ ‚Äî –¥–æ 300–∫ –¥–ª—è —é—Ä–ª–∏—Ü. –ê —É –≤–∞—Å –∫–∞–∫–∞—è —Å–∏—Ç—É–∞—Ü–∏—è, —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å –º–∞—Ä–∫–∏—Ä–æ–≤–∫–æ–π?"



üîß –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ò–°–ü–û–õ–¨–ó–£–ô):
–ö–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –ª—é–±–æ–º —Ç–æ–≤–∞—Ä–µ, —Å—Ä–æ–∫–∞—Ö –∏–ª–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è—Ö ‚Äî –°–ù–ê–ß–ê–õ–ê –≤—ã–∑–æ–≤–∏ get_regulation_info!
–ù–µ –≥–æ–≤–æ—Ä–∏ "–Ω–µ –∑–Ω–∞—é" –∏–ª–∏ "–Ω–µ —É–≤–µ—Ä–µ–Ω–∞" ‚Äî –ø—Ä–æ–≤–µ—Ä—å —á–µ—Ä–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.
–í –±–∞–∑–µ 32 –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ —Ä–∞–∑–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤, –≤–∫–ª—é—á–∞—è –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.

–ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç:
- "–Ω—É–∂–Ω–∞ –ª–∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è X" ‚Üí –≤—ã–∑–æ–≤–∏ get_regulation_info("X")
- "–∫–∞–∫–∏–µ —Å—Ä–æ–∫–∏ –¥–ª—è X" ‚Üí –≤—ã–∑–æ–≤–∏ get_regulation_info("X")
- "–∫–∞–∫–æ–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ X" ‚Üí –≤—ã–∑–æ–≤–∏ get_regulation_info("X")


üìç –ù–ê–í–ò–ì–ê–¶–ò–Ø –ü–û –°–ê–ô–¢–£:
–¢—ã –≤–∏–¥–∏—à—å –Ω–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∫–ª–∏–µ–Ω—Ç (–≤ –∫–æ–Ω—Ü–µ –µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö).
–ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–ø—É—Ç–∞–ª—Å—è –∏–ª–∏ –Ω–µ –º–æ–∂–µ—Ç —á—Ç–æ-—Ç–æ –Ω–∞–π—Ç–∏ ‚Äî –ø–æ–º–æ–≥–∏:
- / –∏–ª–∏ /home ‚Äî –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
- /knowledge ‚Äî –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π, —Å—Ç–∞—Ç—å–∏ –æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ
- /training ‚Äî –æ–±—É—á–µ–Ω–∏–µ, –∫—É—Ä—Å—ã –ø–æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ
- /timeline ‚Äî —Ç–∞–π–º–ª–∞–π–Ω, –¥–∞—Ç—ã –≤–≤–µ–¥–µ–Ω–∏—è –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏
- /partners ‚Äî –ø–∞—Ä—Ç–Ω—ë—Ä—Å–∫–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞
- /about ‚Äî –æ –∫–æ–º–ø–∞–Ω–∏–∏

–ï—Å–ª–∏ –≤–∏–¥–∏—à—å —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∫–∞–∫ —á—Ç–æ-—Ç–æ —Å–¥–µ–ª–∞—Ç—å ‚Äî –ø–æ–¥—Å–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ!
–ù–∞–ø—Ä–∏–º–µ—Ä: "–í–∏–∂—É –≤—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ–±—É—á–µ–Ω–∏—è ‚Äî —Ç–∞–º –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –∫—É—Ä—Å –∏ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è, –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å?"

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."""

def get_system_prompt() -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –ë–î —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π"""
    from datetime import datetime
    today = datetime.now().strftime('%d.%m.%Y')
    
    # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å –¥–∞—Ç–æ–π
    date_prefix = f"""–°–ï–ì–û–î–ù–Ø: {today}
–í—Å–µ–≥–¥–∞ —É—á–∏—Ç—ã–≤–∞–π —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –ø—Ä–∏ –æ—Ç–≤–µ—Ç–∞—Ö –æ —Å—Ä–æ–∫–∞—Ö –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏!
–ï—Å–ª–∏ —Å—Ä–æ–∫ —É–∂–µ –ø—Ä–æ—à—ë–ª ‚Äî –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ –£–ñ–ï –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞.
–ï—Å–ª–∏ —Å—Ä–æ–∫ –≤ –±—É–¥—É—â–µ–º ‚Äî —Ç–æ–ª—å–∫–æ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è.

"""
    
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT setting_value FROM ai_settings WHERE setting_key = 'system_prompt'")
            row = cursor.fetchone()
            if row and row['setting_value']:
                return date_prefix + row['setting_value']
    except Exception as e:
        print(f'[PROMPT] Error loading from DB: {e}')
    return date_prefix + SYSTEM_PROMPT



# ==================== –ü–û–ò–°–ö –ü–û –î–û–ö–£–ú–ï–ù–¢–ê–ú ====================

# –ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
_documents_cache = {}

def load_document(file_path: str) -> str:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ —Ñ–∞–π–ª–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    if file_path in _documents_cache:
        return _documents_cache[file_path]
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        _documents_cache[file_path] = content
        return content
    except Exception as e:
        print(f'[DOCS] Error loading {file_path}: {e}')
        return ''

def search_in_document(content: str, query: str, context_lines: int = 5) -> List[str]:
    """–ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ"""
    if not content or not query:
        return []
    
    lines = content.split('\n')
    query_words = query.lower().split()
    results = []
    
    for i, line in enumerate(lines):
        line_lower = line.lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ö–æ—Ç—è –±—ã 2 —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        matches = sum(1 for word in query_words if word in line_lower and len(word) > 3)
        if matches >= min(2, len(query_words)):
            # –ë–µ—Ä—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
            start = max(0, i - context_lines)
            end = min(len(lines), i + context_lines + 1)
            fragment = '\n'.join(lines[start:end])
            if len(fragment) > 100:  # –¢–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
                results.append(fragment[:1500])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
    
    return results[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞

@tool
def search_tax_code(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –ù–∞–ª–æ–≥–æ–≤–æ–º –∫–æ–¥–µ–∫—Å–µ –†–§. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –Ω–∞–ª–æ–≥–∞—Ö, –ù–î–°, –Ω–∞–ª–æ–≥–æ–≤—ã—Ö —Å—Ç–∞–≤–∫–∞—Ö.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "–ù–î–° –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ", "—Å—Ç–∞–≤–∫–∞ –Ω–∞–ª–æ–≥–∞")
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/nk_rf.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –ù–∞–ª–æ–≥–æ–≤–æ–º –∫–æ–¥–µ–∫—Å–µ –†–§:\n\n" + "\n---\n".join(results)
    return "–í –ù–∞–ª–æ–≥–æ–≤–æ–º –∫–æ–¥–µ–∫—Å–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É. –£—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –Ω–∞—à–∏–º —ç–∫—Å–ø–µ—Ä—Ç–∞–º."

@tool  
def search_customs_code(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –¢–∞–º–æ–∂–µ–Ω–Ω–æ–º –∫–æ–¥–µ–∫—Å–µ –ï–ê–≠–°. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ —Ç–∞–º–æ–∂–Ω–µ, –∏–º–ø–æ—Ä—Ç–µ, —ç–∫—Å–ø–æ—Ä—Ç–µ, –¥–µ–∫–ª–∞—Ä–∏—Ä–æ–≤–∞–Ω–∏–∏.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "—Ç–∞–º–æ–∂–µ–Ω–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ", "–¥–µ–∫–ª–∞—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤")
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/tk_eaes.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –¢–∞–º–æ–∂–µ–Ω–Ω–æ–º –∫–æ–¥–µ–∫—Å–µ –ï–ê–≠–°:\n\n" + "\n---\n".join(results)
    return "–í –¢–∞–º–æ–∂–µ–Ω–Ω–æ–º –∫–æ–¥–µ–∫—Å–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É."

@tool
def search_customs_law(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –§–ó-289 –æ —Ç–∞–º–æ–∂–µ–Ω–Ω–æ–º —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ–¥—É—Ä–∞—Ö –≤ –†–æ—Å—Å–∏–∏.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/fz_289_customs.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –§–ó-289 –æ —Ç–∞–º–æ–∂–µ–Ω–Ω–æ–º —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏:\n\n" + "\n---\n".join(results)
    return "–í –∑–∞–∫–æ–Ω–µ –æ —Ç–∞–º–æ–∂–µ–Ω–Ω–æ–º —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

@tool
def search_currency_law(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –§–ó-173 –æ –≤–∞–ª—é—Ç–Ω–æ–º —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –≤–∞–ª—é—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö, –≤–∞–ª—é—Ç–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–µ.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "–≤–∞–ª—é—Ç–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å", "—Ä–µ–ø–∞—Ç—Ä–∏–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏")
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/fz_173_currency.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –§–ó-173 –æ –≤–∞–ª—é—Ç–Ω–æ–º —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏:\n\n" + "\n---\n".join(results)
    return "–í –∑–∞–∫–æ–Ω–µ –æ –≤–∞–ª—é—Ç–Ω–æ–º —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

@tool
def search_admin_code(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –ö–æ–ê–ü –†–§. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ —à—Ç—Ä–∞—Ñ–∞—Ö, –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "—à—Ç—Ä–∞—Ñ –∑–∞ –º–∞—Ä–∫–∏—Ä–æ–≤–∫—É", "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å")
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/koap_rf.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –ö–æ–ê–ü –†–§:\n\n" + "\n---\n".join(results)
    return "–í –ö–æ–ê–ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É."

@tool
def search_marking_law(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –ü–ü-515 –æ —Å–∏—Å—Ç–µ–º–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –ø—Ä–∞–≤–∏–ª–∞—Ö –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞", "–ø—Ä–∞–≤–∏–ª–∞ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏")
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/pp_515_marking.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –ü–ü-515 –æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ:\n\n" + "\n---\n".join(results)
    return "–í –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

@tool
def search_accounting_rules(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –ü–ë–£ 3/2006. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–º —É—á—ë—Ç–µ –≤–∞–ª—é—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "–∫—É—Ä—Å–æ–≤—ã–µ —Ä–∞–∑–Ω–∏—Ü—ã", "—É—á—ë—Ç –≤–∞–ª—é—Ç—ã")
    """
    content = load_document('/var/www/promarkirui/backend/knowledge_base/ved/pbu_3_2006.txt')
    results = search_in_document(content, query)
    
    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ –≤ –ü–ë–£ 3/2006:\n\n" + "\n---\n".join(results)
    return "–í –ü–ë–£ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É."



# ==================== –°–ü–†–ê–í–û–ß–ù–ò–ö –ü–û–°–¢–ê–ù–û–í–õ–ï–ù–ò–ô ====================

_regulations_cache = None

def load_regulations():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π"""
    global _regulations_cache
    if _regulations_cache is not None:
        return _regulations_cache
    
    try:
        with open('/var/www/promarkirui/backend/knowledge_base/regulations.json', 'r', encoding='utf-8') as f:
            _regulations_cache = json.load(f)
        return _regulations_cache
    except Exception as e:
        print(f'[REGULATIONS] Error loading: {e}')
        return {'regulations': [], 'fines': {}}

@tool
def get_regulation_info(product_query: str) -> str:
    """
    –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –ª—é–±–æ–º —Ç–æ–≤–∞—Ä–µ, —Å—Ä–æ–∫–∞—Ö, –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è—Ö –∏–ª–∏ –Ω—É–∂–Ω–∞ –ª–∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–º–µ—Ä –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è, —Å—Ä–æ–∫–∏, —ç—Ç–∞–ø—ã –∏ –¥–ª—è –∫–æ–≥–æ –¥–µ–π—Å—Ç–≤—É–µ—Ç.
    
    Args:
        product_query: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "–º–æ–ª–æ–∫–æ", "–æ–±—É–≤—å", "—à–∏–Ω—ã", "–ø–∏–≤–æ")
    """
    data = load_regulations()
    query = product_query.lower()
    found = []
    
    for reg in data.get('regulations', []):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∏–ª–∏ —Ç–æ–≤–∞—Ä–∞–º–∏
        products = [p.lower() for p in reg.get('products', [])]
        title = reg.get('title', '').lower()
        
        if query in title or any(query in p for p in products):
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏
            info = f"**–ü–ü –†–§ ‚Ññ{reg['number']}** –æ—Ç {reg['date']}\n"
            info += f"{reg['title']}\n\n"
            
            # –¢–æ–≤–∞—Ä—ã
            info += f"–¢–æ–≤–∞—Ä—ã: {', '.join(reg.get('products', [])[:5])}"
            if len(reg.get('products', [])) > 5:
                info += " –∏ –¥—Ä."
            info += "\n"
            
            # –°—Ä–æ–∫–∏
            if reg.get('start_date'):
                info += f"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞: {reg['start_date']}\n"
            
            if reg.get('milestones'):
                info += "–≠—Ç–∞–ø—ã:\n"
                for m in reg['milestones'][:4]:
                    info += f"  ‚Ä¢ {m['date']}: {m['description']}\n"
            
            # –°—É–±—ä–µ–∫—Ç—ã
            if reg.get('subjects'):
                info += f"–î–ª—è –∫–æ–≥–æ: {', '.join(reg['subjects'][:4])}\n"
            
            # –°—Ç–∞—Ç—É—Å
            status_text = "–î–µ–π—Å—Ç–≤—É–µ—Ç" if reg.get('status') == 'active' else "–ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è"

            # –î–µ—Ç–∞–ª–∏ (–æ—Å—Ç–∞—Ç–∫–∏, –ø–µ—Ä–µ—Ö–æ–¥–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã)
            if reg.get("details"):
                info += "\n\n**–í–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏:**\n"
                for key, value in reg["details"].items():
                    info += f"‚Ä¢ {key}: {value}\n"
            info += f"–°—Ç–∞—Ç—É—Å: {status_text}"
            
            found.append(info)
    
    if found:
        result = "–ù–∞–π–¥–µ–Ω—ã –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ:\n\n" + "\n---\n".join(found[:3])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à—Ç—Ä–∞—Ñ–∞—Ö
        fines = data.get('fines', {})
        if fines:
            result += "\n\n**–®—Ç—Ä–∞—Ñ—ã –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è:**\n"
            result += f"‚Ä¢ –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ/–≤–≤–æ–∑ –±–µ–∑ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏: –¥–æ 100 000 ‚ÇΩ –¥–ª—è —é—Ä–ª–∏—Ü\n"
            result += f"‚Ä¢ –ü—Ä–æ–¥–∞–∂–∞ –±–µ–∑ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏: –¥–æ 300 000 ‚ÇΩ –¥–ª—è —é—Ä–ª–∏—Ü + –∫–æ–Ω—Ñ–∏—Å–∫–∞—Ü–∏—è"
        
        return result
    
    return f"–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ –º–∞—Ä–∫–∏—Ä–æ–≤–∫–µ '{product_query}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –£—Ç–æ—á–Ω–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞."
# ==================== –°–û–ó–î–ê–ù–ò–ï –ê–ì–ï–ù–¢–ê ====================

@tool
def search_in_regulation(query: str, product: str) -> str:
    """
    –ü–æ–∏—Å–∫ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –¥–µ—Ç–∞–ª—è—Ö: –ø–µ—Ä–µ—Ö–æ–¥–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã, –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –¥–ª—è –∫–æ–≥–æ –¥–µ–π—Å—Ç–≤—É–µ—Ç, –Ω—é–∞–Ω—Å—ã.
    –°–∫–∞–∂–∏ –∫–ª–∏–µ–Ω—Ç—É: "–°–µ–∫—É–Ω–¥—É, —Å–≤–µ—Ä—é—Å—å —Å –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º..."
    
    Args:
        query: –ß—Ç–æ –∏—â–µ–º ("–ø–µ—Ä–µ—Ö–æ–¥–Ω—ã–π –ø–µ—Ä–∏–æ–¥", "–∏—Å–∫–ª—é—á–µ–Ω–∏—è", "–¥–ª—è –∫–æ–≥–æ", "–æ—Å—Ç–∞—Ç–∫–∏", "—à—Ç—Ä–∞—Ñ—ã")
        product: –¢–æ–≤–∞—Ä ("—Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–µ –ø–∏—Ç–∞–Ω–∏–µ", "–æ–±—É–≤—å", "–º–æ–ª–æ–∫–æ")
    """
    import subprocess
    import os
    
    regulations_dir = '/var/www/promarkirui/backend/knowledge_base/regulations/'
    
    product_keywords = {
        '—Å–ø–æ—Ä—Ç': ['811', '31_–º–∞—è_2025'],
        '–æ–±—É–≤': ['860', '5_–∏—é–ª—è_2019'],
        '–º–æ–ª–æ–∫': ['2099', '15_–¥–µ–∫–∞–±—Ä—è_2020'],
        '–æ–¥–µ–∂–¥': ['1956', '31_–¥–µ–∫–∞–±—Ä—è_2019'],
        '—Ç–µ–∫—Å—Ç–∏–ª': ['1956'],
        '–ø–∏–≤': ['2173', '30_–Ω–æ—è–±—Ä—è_2022'],
        '–¥–µ—Ç': ['819', '31_–º–∞—è_2025'],
        '–∏–≥—Ä—É—à': ['819'],
        '—Å—Ç—Ä–æ–π': ['820', '31_–º–∞—è_2025'],
        '—à–∏–Ω': ['1958', '31_–¥–µ–∫–∞–±—Ä—è_2019'],
        '–ª–µ–∫–∞—Ä—Å—Ç–≤': ['1556', '14_–¥–µ–∫–∞–±—Ä—è_2018'],
        '—Ç–∞–±–∞–∫': ['224', '28_—Ñ–µ–≤—Ä–∞–ª—è_2019'],
        '–º–µ—Ö': ['787', '11_–∞–≤–≥—É—Å—Ç–∞_2016'],
        '–ø–∞—Ä—Ñ—é–º': ['1957', '31_–¥–µ–∫–∞–±—Ä—è_2019'],
        '—Ñ–æ—Ç–æ': ['1953', '31_–¥–µ–∫–∞–±—Ä—è_2019'],
        '–≤–æ–¥': ['841', '31_–º–∞—è_2021'],
        '—Å–æ–∫': ['887', '31_–º–∞—è_2023'],
        '–±–∞–¥': ['886', '31_–º–∞—è_2023'],
        '–∏–∫—Ä': ['2028', '29_–Ω–æ—è–±—Ä—è_2023'],
        '–≤–µ–ª–æ—Å–∏–ø–µ–¥': ['645', '23_–º–∞—è_2024'],
        '–∫–æ—Ä–º': ['674', '27_–º–∞—è_2024'],
        '–º–∞—Å–ª': ['676', '27_–º–∞—è_2024'],
        '–∫–æ–Ω—Å–µ—Ä–≤': ['677', '27_–º–∞—è_2024'],
    }
    
    target_files = []
    product_lower = product.lower()
    
    for key, patterns in product_keywords.items():
        if key in product_lower:
            for f in os.listdir(regulations_dir):
                f_lower = f.lower()
                for pattern in patterns:
                    if pattern.lower() in f_lower or pattern in f:
                        target_files.append(f)
            break
    
    if not target_files:
        target_files = [f for f in os.listdir(regulations_dir) if f.endswith('.rtf')][:3]
    
    results = []
    query_words = [w for w in query.lower().split() if len(w) > 3]
    
    for filename in list(set(target_files))[:2]:
        filepath = os.path.join(regulations_dir, filename)
        try:
            result = subprocess.run(
                ['textutil', '-convert', 'txt', '-stdout', filepath],
                capture_output=True, text=True, timeout=15
            )
            content = result.stdout
            if not content:
                continue
                
            lines = content.split('\n')
            
            for i, line in enumerate(lines):
                line_lower = line.lower()
                
                if any(word in line_lower for word in query_words) or any(kw in line_lower for kw in ['–¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è', '–≤–ø—Ä–∞–≤–µ', '–æ–±—è–∑–∞–Ω', '–ø–æ 31', '—Å 1 –æ–∫—Ç—è–±—Ä—è', '—Å 1 –¥–µ–∫–∞–±—Ä—è']):
                    start = max(0, i - 1)
                    end = min(len(lines), i + 4)
                    fragment = ' '.join(lines[start:end]).strip()
                    
                    if len(fragment) > 100 and fragment[:100] not in str(results):
                        results.append(fragment[:600])
                        if len(results) >= 4:
                            break
                            
        except Exception as e:
            print(f'[SEARCH_REG] Error: {e}')
            continue
    
    if results:
        return f"–ò–∑ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ '{product}':\n\n" + "\n\n---\n\n".join(results[:3])
    
    return f"–î–µ—Ç–∞–ª–∏ –ø–æ '{query}' –¥–ª—è '{product}' –ª—É—á—à–µ —É—Ç–æ—á–Ω–∏—Ç—å —É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤."


_agent = None

def create_agent():
    """–°–æ–∑–¥–∞—Ç—å LangGraph –∞–≥–µ–Ω—Ç–∞"""
    model = ChatAnthropic(
        model="claude-sonnet-4-20250514",
        temperature=0.3,
        max_tokens=1024,
        api_key=ANTHROPIC_API_KEY
    )

    tools = [
        search_product,
        check_tnved,
        get_fines,
        get_equipment,
        get_registration_guide,
        site_help,
        create_request,
        call_manager,
        # –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º (–í–≠–î, –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è)
        search_tax_code,
        search_customs_code,
        search_customs_law,
        search_currency_law,
        search_admin_code,
        search_marking_law,
        search_accounting_rules,
        # –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π
        get_regulation_info,
        # –ü–æ–∏—Å–∫ –¥–µ—Ç–∞–ª–µ–π –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        search_in_regulation
    ]

    model_with_tools = model.bind_tools(tools)

    graph = StateGraph(AgentState)

    def call_model(state: AgentState):
        messages = state["messages"]
        system = SystemMessage(content=get_system_prompt())
        response = model_with_tools.invoke([system] + messages)
        return {"messages": [response]}

    def should_continue(state: AgentState) -> Literal["tools", "__end__"]:
        last_message = state["messages"][-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools"
        return "__end__"

    graph.add_node("agent", call_model)
    graph.add_node("tools", ToolNode(tools))

    graph.set_entry_point("agent")
    graph.add_conditional_edges("agent", should_continue)
    graph.add_edge("tools", "agent")

    return graph.compile()


def get_agent():
    """–ü–æ–ª—É—á–∏—Ç—å –∞–≥–µ–Ω—Ç–∞ (singleton)"""
    global _agent
    if _agent is None:
        _agent = create_agent()
    return _agent


# ==================== –†–û–£–¢–ï–† ====================

router = APIRouter(prefix='/ai', tags=['AI Consultant'])


def get_settings() -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT setting_key, setting_value FROM ai_settings')
        return {row['setting_key']: row['setting_value'] for row in cursor.fetchall()}


def check_quick_reply(message: str) -> Optional[str]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤"""
    message_lower = message.lower().strip()

    # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞–∫ –≤–æ–ø—Ä–æ—Å–∞ ‚Äî —ç—Ç–æ –≤–æ–ø—Ä–æ—Å, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º quick reply
    if '?' in message_lower:
        return None

    # –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏)
    if len(message_lower) > 25:
        return None

    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT trigger_words, response FROM ai_quick_replies WHERE is_active = 1')

        for row in cursor.fetchall():
            triggers = [t.strip().lower() for t in row['trigger_words'].split(',')]
            for trigger in triggers:
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —Ç—Ä–∏–≥–≥–µ—Ä + –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                if message_lower == trigger or message_lower in [trigger + '!', trigger + '.', trigger + ',']:
                    return row['response']

    return None


@router.post('/chat')
async def chat_endpoint(data: ChatMessage):
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç —á–∞—Ç–∞"""
    settings = get_settings()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –±–æ—Ç–∞
    if settings.get('is_active') != 'true':
        return {"response": "–ë–æ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∑–≤–æ–Ω–∏—Ç–µ –Ω–∞–º!", "session_id": data.session_id}

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã
    quick = check_quick_reply(data.message)
    if quick:
        return {"response": quick, "session_id": data.session_id or str(uuid.uuid4())}

    # –°–æ–∑–¥–∞—ë–º/–ø–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
    session_id = data.session_id or str(uuid.uuid4())

    with get_db() as conn:
        cursor = conn.cursor()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞
        cursor.execute('SELECT id FROM ai_conversations WHERE session_id = ?', (session_id,))
        conv = cursor.fetchone()

        if not conv:
            cursor.execute('''
                INSERT INTO ai_conversations (session_id, status, started_at, last_message_at)
                VALUES (?, 'active', ?, ?)
            ''', (session_id, datetime.now().isoformat(), datetime.now().isoformat()))
            conn.commit()
            conv_id = cursor.lastrowid
        else:
            conv_id = conv['id']

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        cursor.execute('''
            INSERT INTO ai_messages (conversation_id, role, content, created_at)
            VALUES (?, 'user', ?, ?)
        ''', (conv_id, data.message, datetime.now().isoformat()))
        conn.commit()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        cursor.execute('''
            SELECT role, content FROM ai_messages
            WHERE conversation_id = ?
            ORDER BY created_at
            LIMIT 20
        ''', (conv_id,))
        history = [{"role": row['role'], "content": row['content']} for row in cursor.fetchall()]

    # –í—ã–∑—ã–≤–∞–µ–º –∞–≥–µ–Ω—Ç–∞
    try:
        agent = get_agent()

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é
        messages = []
        for msg in history[:-1]:  # –ë–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ (—Ç–µ–∫—É—â–µ–≥–æ) —Å–æ–æ–±—â–µ–Ω–∏—è
            if msg["role"] == "user":
                messages.append(HumanMessage(content=msg["content"]))
            else:
                messages.append(AIMessage(content=msg["content"]))

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        page_context = ""
        if data.current_page:
            page_context = "\n[–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: " + data.current_page + "]"
            if data.page_title:
                page_context += f" ({data.page_title})"
        
        messages.append(HumanMessage(content=data.message + page_context))

        # –í—ã–∑–æ–≤ –∞–≥–µ–Ω—Ç–∞
        result = agent.invoke({"messages": messages})
        response_content = result["messages"][-1].content

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ ‚Äî –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ —Å–ø–∏—Å–∫–æ–º
        if isinstance(response_content, list):
            # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞—Å—Ç–∏
            response_text = ""
            for item in response_content:
                if isinstance(item, dict) and item.get("type") == "text":
                    response_text += item.get("text", "")
                elif isinstance(item, str):
                    response_text += item
            if not response_text:
                response_text = "–ü—Ä–æ—Å—Ç–∏—Ç–µ, –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑)"
        else:
            response_text = str(response_content)

        # –°—á–∏—Ç–∞–µ–º —Ç–æ–∫–µ–Ω—ã (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
        input_tokens = sum(len(str(m.content)) // 4 for m in messages)
        output_tokens = len(response_text) // 4

    except Exception as e:
        print(f"Agent error: {e}")
        response_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –ø–æ–∑–≤–æ–Ω–∏—Ç–µ –Ω–∞–º!"
        input_tokens = 0
        output_tokens = 0

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç
    with get_db() as conn:
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO ai_messages (conversation_id, role, content, tokens_input, tokens_output, created_at)
            VALUES (?, 'assistant', ?, ?, ?, ?)
        ''', (conv_id, response_text, input_tokens, output_tokens, datetime.now().isoformat()))

        cursor.execute('''
            UPDATE ai_conversations SET last_message_at = ? WHERE id = ?
        ''', (datetime.now().isoformat(), conv_id))

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
        model = settings.get('model', 'claude-sonnet-4-20250514')
        pricing = PRICING.get(model, PRICING['claude-sonnet-4-20250514'])
        cost = (input_tokens * pricing['input'] + output_tokens * pricing['output']) / 1_000_000

        cursor.execute('''
            INSERT INTO ai_token_usage (conversation_id, model, tokens_input, tokens_output, cost_usd)
            VALUES (?, ?, ?, ?, ?)
        ''', (conv_id, model, input_tokens, output_tokens, cost))

        conn.commit()

    return {"response": response_text, "session_id": session_id}


# ==================== –û–°–¢–ê–õ–¨–ù–´–ï –≠–ù–î–ü–û–ò–ù–¢–´ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ====================

@router.get('/stats')
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ AI"""
    with get_db() as conn:
        cursor = conn.cursor()

        today = datetime.now().strftime('%Y-%m-%d')

        # –î–∏–∞–ª–æ–≥–∏
        cursor.execute('SELECT COUNT(*) as total FROM ai_conversations')
        total_convs = cursor.fetchone()['total']

        cursor.execute('SELECT COUNT(*) as today FROM ai_conversations WHERE date(started_at) = ?', (today,))
        today_convs = cursor.fetchone()['today']

        cursor.execute("SELECT COUNT(*) as leads FROM ai_conversations WHERE status = 'lead'")
        leads = cursor.fetchone()['leads']

        # –¢–æ–∫–µ–Ω—ã
        cursor.execute('SELECT SUM(tokens_input) as inp, SUM(tokens_output) as out, SUM(cost_usd) as cost FROM ai_token_usage')
        tokens = cursor.fetchone()

        cursor.execute('SELECT SUM(cost_usd) as cost FROM ai_token_usage WHERE date(created_at) = ?', (today,))
        today_cost = cursor.fetchone()['cost'] or 0

        # –ü–æ –¥–Ω—è–º
        cursor.execute('''
            SELECT date(created_at) as date, SUM(cost_usd) as cost, COUNT(*) as requests
            FROM ai_token_usage
            GROUP BY date(created_at)
            ORDER BY date DESC
            LIMIT 7
        ''')
        daily = [{"date": row['date'], "cost": row['cost'], "requests": row['requests']} for row in cursor.fetchall()]

        return {
            "conversations": {"total": total_convs, "today": today_convs, "leads": leads},
            "tokens": {
                "total_input": tokens['inp'] or 0,
                "total_output": tokens['out'] or 0,
                "total_cost_usd": tokens['cost'] or 0,
                "today_cost_usd": today_cost
            },
            "daily": daily
        }


@router.get('/conversations')
async def get_conversations():
    """–°–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            SELECT c.*,
                   (SELECT content FROM ai_messages WHERE conversation_id = c.id AND role = 'user' ORDER BY created_at LIMIT 1) as first_message,
                   (SELECT COUNT(*) FROM ai_messages WHERE conversation_id = c.id) as message_count
            FROM ai_conversations c
            ORDER BY c.last_message_at DESC
            LIMIT 100
        ''')
        return [dict(row) for row in cursor.fetchall()]


@router.get('/conversations/{conv_id}')
async def get_conversation(conv_id: int):
    """–î–µ—Ç–∞–ª–∏ –¥–∏–∞–ª–æ–≥–∞"""
    with get_db() as conn:
        cursor = conn.cursor()

        cursor.execute('SELECT * FROM ai_conversations WHERE id = ?', (conv_id,))
        conv = cursor.fetchone()
        if not conv:
            raise HTTPException(404, "Conversation not found")

        cursor.execute('SELECT * FROM ai_messages WHERE conversation_id = ? ORDER BY created_at', (conv_id,))
        messages = [dict(row) for row in cursor.fetchall()]

        return {"conversation": dict(conv), "messages": messages}


@router.get('/settings')
async def get_settings_endpoint():
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"""
    return get_settings()


@router.post('/settings')
async def update_settings(data: SettingsUpdate):
    """–û–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫—É"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO ai_settings (setting_key, setting_value)
            VALUES (?, ?)
            ON CONFLICT(setting_key) DO UPDATE SET setting_value = excluded.setting_value
        ''', (data.setting_key, data.setting_value))
        conn.commit()
    return {"success": True}


@router.get('/knowledge')
async def get_knowledge():
    """–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM ai_knowledge_base ORDER BY priority DESC')
        return [dict(row) for row in cursor.fetchall()]


@router.post('/knowledge')
async def add_knowledge(data: KnowledgeItem):
    """–î–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO ai_knowledge_base (category, question, answer, priority, is_active)
            VALUES (?, ?, ?, ?, 1)
        ''', (data.category, data.question, data.answer, data.priority))
        conn.commit()
        return {"id": cursor.lastrowid}


@router.delete('/knowledge/{item_id}')
async def delete_knowledge(item_id: int):
    """–£–¥–∞–ª–∏—Ç—å –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('DELETE FROM ai_knowledge_base WHERE id = ?', (item_id,))
        conn.commit()
    return {"success": True}


@router.get('/quick-replies')
async def get_quick_replies():
    """–ü–æ–ª—É—á–∏—Ç—å –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM ai_quick_replies ORDER BY id')
        return [dict(row) for row in cursor.fetchall()]


@router.post('/quick-replies')
async def add_quick_reply(data: QuickReply):
    """–î–æ–±–∞–≤–∏—Ç—å –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO ai_quick_replies (trigger_words, response, is_active)
            VALUES (?, ?, 1)
        ''', (data.trigger_words, data.response))
        conn.commit()
        return {"id": cursor.lastrowid}


@router.delete('/quick-replies/{item_id}')
async def delete_quick_reply(item_id: int):
    """–£–¥–∞–ª–∏—Ç—å –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('DELETE FROM ai_quick_replies WHERE id = ?', (item_id,))
        conn.commit()
    return {"success": True}


# ==================== –ò–°–¢–û–ß–ù–ò–ö–ò –î–ê–ù–ù–´–• (Data Sources) ====================

class DataSourceCreate(BaseModel):
    name: str
    source_type: str  # tool, document, faq, api
    category: str     # marking, ved, accounting, general
    description: str
    file_path: Optional[str] = None
    is_active: bool = True

@router.get('/data-sources')
async def get_data_sources():
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö AI"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, name, source_type, category, description, 
                   file_path, file_size, is_active, last_updated, created_at
            FROM ai_data_sources 
            ORDER BY source_type, category, name
        ''')
        sources = [dict(row) for row in cursor.fetchall()]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        grouped = {
            'tools': [s for s in sources if s['source_type'] == 'tool'],
            'documents': [s for s in sources if s['source_type'] == 'document'],
            'faq': [s for s in sources if s['source_type'] == 'faq'],
            'api': [s for s in sources if s['source_type'] == 'api']
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            'total': len(sources),
            'active': len([s for s in sources if s['is_active']]),
            'by_category': {}
        }
        for s in sources:
            cat = s['category'] or 'other'
            stats['by_category'][cat] = stats['by_category'].get(cat, 0) + 1
            
        return {
            'sources': sources,
            'grouped': grouped,
            'stats': stats
        }

@router.post('/data-sources')
async def create_data_source(data: DataSourceCreate):
    """–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO ai_data_sources (name, source_type, category, description, file_path, is_active)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (data.name, data.source_type, data.category, data.description, data.file_path, 1 if data.is_active else 0))
        conn.commit()
        return {'success': True, 'id': cursor.lastrowid}

@router.put('/data-sources/{source_id}')
async def update_data_source(source_id: int, data: dict):
    """–û–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (–≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å)"""
    with get_db() as conn:
        cursor = conn.cursor()
        if 'is_active' in data:
            cursor.execute('UPDATE ai_data_sources SET is_active = ?, last_updated = CURRENT_TIMESTAMP WHERE id = ?', 
                          (1 if data['is_active'] else 0, source_id))
        if 'description' in data:
            cursor.execute('UPDATE ai_data_sources SET description = ?, last_updated = CURRENT_TIMESTAMP WHERE id = ?',
                          (data['description'], source_id))
        conn.commit()
        return {'success': True}

@router.delete('/data-sources/{source_id}')
async def delete_data_source(source_id: int):
    """–£–¥–∞–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('DELETE FROM ai_data_sources WHERE id = ?', (source_id,))
        conn.commit()
        return {'success': True}


# ==================== –°–ö–ê–ß–ò–í–ê–ù–ò–ï –î–û–ö–£–ú–ï–ù–¢–û–í ====================

from fastapi.responses import FileResponse

@router.get('/documents/{source_id}/download')
async def download_document(source_id: int):
    """–°–∫–∞—á–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT name, file_path FROM ai_data_sources WHERE id = ? AND source_type = ?', (source_id, 'document'))
        row = cursor.fetchone()
        
        if not row:
            raise HTTPException(404, '–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω')
        
        file_path = row['file_path']
        filename = row['name'].replace(' ', '_') + '.txt'
        
        if not os.path.exists(file_path):
            raise HTTPException(404, '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ')
        
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type='text/plain; charset=utf-8'
        )

